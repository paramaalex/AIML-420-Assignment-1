{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2037bcd0-530b-4cbe-a2dc-b395f9182edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
      "0  ...         25.38          17.33           184.60      2019.0   \n",
      "1  ...         24.99          23.41           158.80      1956.0   \n",
      "2  ...         23.57          25.53           152.50      1709.0   \n",
      "3  ...         14.91          26.50            98.87       567.7   \n",
      "4  ...         22.54          16.67           152.20      1575.0   \n",
      "\n",
      "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   symmetry_worst  fractal_dimension_worst  \n",
      "0          0.4601                  0.11890  \n",
      "1          0.2750                  0.08902  \n",
      "2          0.3613                  0.08758  \n",
      "3          0.6638                  0.17300  \n",
      "4          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 32 columns]\n",
      "\n",
      "Using None:\n",
      "KNN metrics: {'Accuracy': 0.7134502923976608, 'Precision': 0.6296296296296297, 'Recall': 0.5396825396825397, 'F1 Score': 0.5811965811965812}\n",
      "Decision Tree metrics: {'Accuracy': 0.935672514619883, 'Precision': 0.8823529411764706, 'Recall': 0.9523809523809523, 'F1 Score': 0.916030534351145}\n",
      "\n",
      "Using StandardScaler:\n",
      "KNN metrics: {'Accuracy': 0.9590643274853801, 'Precision': 0.9516129032258065, 'Recall': 0.9365079365079365, 'F1 Score': 0.944}\n",
      "Decision Tree metrics: {'Accuracy': 0.935672514619883, 'Precision': 0.8823529411764706, 'Recall': 0.9523809523809523, 'F1 Score': 0.916030534351145}\n",
      "\n",
      "Using MinMaxScaler:\n",
      "KNN metrics: {'Accuracy': 0.9766081871345029, 'Precision': 0.9836065573770492, 'Recall': 0.9523809523809523, 'F1 Score': 0.967741935483871}\n",
      "Decision Tree metrics: {'Accuracy': 0.935672514619883, 'Precision': 0.8823529411764706, 'Recall': 0.9523809523809523, 'F1 Score': 0.916030534351145}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KNN (k=3):\n",
      "Mean Accuracy: 0.7734, Std Dev: 0.0683\n",
      "Mean F1 Score: 0.6550, Std Dev: 0.0861\n",
      "\n",
      "KNN (k=9):\n",
      "Mean Accuracy: 0.7190, Std Dev: 0.0618\n",
      "Mean F1 Score: 0.4874, Std Dev: 0.0813\n",
      "\n",
      "Decision Tree (max_depth=2):\n",
      "Mean Accuracy: 0.9209, Std Dev: 0.0265\n",
      "Mean F1 Score: 0.8896, Std Dev: 0.0431\n",
      "\n",
      "Decision Tree (max_depth=8):\n",
      "Mean Accuracy: 0.9367, Std Dev: 0.0285\n",
      "Mean F1 Score: 0.9117, Std Dev: 0.0444\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'breast-cancer.csv' with your actual file path\n",
    "df = pd.read_csv(\"breast-cancer.csv\")\n",
    "print(df.head())\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Assume missing values are represented by 0 in numerical columns.\n",
    "# Replace 0 with np.nan for proper imputation.\n",
    "df_numeric = df.copy()\n",
    "columns_to_impute = df_numeric.columns.drop(\"diagnosis\")  # adjust as needed\n",
    "df_numeric[columns_to_impute] = df_numeric[columns_to_impute].replace(0, np.nan)\n",
    "\n",
    "# Mean imputation\n",
    "imputer_mean = SimpleImputer(strategy=\"mean\")\n",
    "X_mean = imputer_mean.fit_transform(df_numeric[columns_to_impute])\n",
    "\n",
    "# Median imputation\n",
    "imputer_median = SimpleImputer(strategy=\"median\")\n",
    "X_median = imputer_median.fit_transform(df_numeric[columns_to_impute])\n",
    "\n",
    "# You can then attach the target variable back and evaluate a classifier\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Split the dataset (assume X and y are prepared after imputation)\n",
    "X = X_mean  # or X_median\n",
    "y = df[\"diagnosis\"].map({'M':1, 'B':0}).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "}\n",
    "\n",
    "# Define scalers\n",
    "scalers = {\n",
    "    \"None\": None,\n",
    "    \"StandardScaler\": StandardScaler(),\n",
    "    \"MinMaxScaler\": MinMaxScaler()\n",
    "}\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1 Score\": f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    if scaler:\n",
    "        scaler.fit(X_train)\n",
    "        X_train_scaled = scaler.transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train_scaled, X_test_scaled = X_train, X_test\n",
    "\n",
    "    print(f\"\\nUsing {scaler_name}:\")\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        metrics = evaluate_model(model, X_test_scaled, y_test)\n",
    "        print(f\"{model_name} metrics: {metrics}\")\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "\n",
    "results = {\"Classifier\": [], \"Hyperparameter\": [], \"Value\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1 Score\": []}\n",
    "\n",
    "# KNN hyperparameter tuning\n",
    "for k in [3, 9, 15, 21]:\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    metrics = evaluate_model(model, X_test, y_test)\n",
    "    results[\"Classifier\"].append(\"KNN\")\n",
    "    results[\"Hyperparameter\"].append(\"n_neighbors\")\n",
    "    results[\"Value\"].append(k)\n",
    "    results[\"Accuracy\"].append(metrics[\"Accuracy\"])\n",
    "    results[\"Precision\"].append(metrics[\"Precision\"])\n",
    "    results[\"Recall\"].append(metrics[\"Recall\"])\n",
    "    results[\"F1 Score\"].append(metrics[\"F1 Score\"])\n",
    "\n",
    "# Decision Tree hyperparameter tuning\n",
    "for depth in [2, 8, 14]:\n",
    "    model = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    metrics = evaluate_model(model, X_test, y_test)\n",
    "    results[\"Classifier\"].append(\"Decision Tree\")\n",
    "    results[\"Hyperparameter\"].append(\"max_depth\")\n",
    "    results[\"Value\"].append(depth)\n",
    "    results[\"Accuracy\"].append(metrics[\"Accuracy\"])\n",
    "    results[\"Precision\"].append(metrics[\"Precision\"])\n",
    "    results[\"Recall\"].append(metrics[\"Recall\"])\n",
    "    results[\"F1 Score\"].append(metrics[\"F1 Score\"])\n",
    "\n",
    "# AdaBoost hyperparameter tuning\n",
    "for n in [10, 20, 30]:\n",
    "    model = AdaBoostClassifier(n_estimators=n, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    metrics = evaluate_model(model, X_test, y_test)\n",
    "    results[\"Classifier\"].append(\"AdaBoost\")\n",
    "    results[\"Hyperparameter\"].append(\"n_estimators\")\n",
    "    results[\"Value\"].append(n)\n",
    "    results[\"Accuracy\"].append(metrics[\"Accuracy\"])\n",
    "    results[\"Precision\"].append(metrics[\"Precision\"])\n",
    "    results[\"Recall\"].append(metrics[\"Recall\"])\n",
    "    results[\"F1 Score\"].append(metrics[\"F1 Score\"])\n",
    "\n",
    "# Random Forest hyperparameter tuning\n",
    "for n in [10, 30, 50, 60]:\n",
    "    model = RandomForestClassifier(n_estimators=n, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    metrics = evaluate_model(model, X_test, y_test)\n",
    "    results[\"Classifier\"].append(\"Random Forest\")\n",
    "    results[\"Hyperparameter\"].append(\"n_estimators\")\n",
    "    results[\"Value\"].append(n)\n",
    "    results[\"Accuracy\"].append(metrics[\"Accuracy\"])\n",
    "    results[\"Precision\"].append(metrics[\"Precision\"])\n",
    "    results[\"Recall\"].append(metrics[\"Recall\"])\n",
    "    results[\"F1 Score\"].append(metrics[\"F1 Score\"])\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "models = {\n",
    "    \"KNN (k=3)\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"KNN (k=9)\": KNeighborsClassifier(n_neighbors=9),\n",
    "    \"Decision Tree (max_depth=2)\": DecisionTreeClassifier(max_depth=2, random_state=42),\n",
    "    \"Decision Tree (max_depth=8)\": DecisionTreeClassifier(max_depth=8, random_state=42)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    cv_results = cross_validate(model, X, y, cv=cv, scoring=['accuracy', 'f1'])\n",
    "    mean_acc = cv_results['test_accuracy'].mean()\n",
    "    std_acc = cv_results['test_accuracy'].std()\n",
    "    mean_f1 = cv_results['test_f1'].mean()\n",
    "    std_f1 = cv_results['test_f1'].std()\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Mean Accuracy: {mean_acc:.4f}, Std Dev: {std_acc:.4f}\")\n",
    "    print(f\"Mean F1 Score: {mean_f1:.4f}, Std Dev: {std_f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2a089-e92c-4388-ad30-ecb74eb8d8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32dea8-398a-4417-90fb-aec1e6ba4344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b49d873-aaf6-499e-a251-35923d03c9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
